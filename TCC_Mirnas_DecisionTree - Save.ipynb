{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f550bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Grupo</th>\n",
       "      <th>MIMAT0000062_st</th>\n",
       "      <th>MIMAT0000063_st</th>\n",
       "      <th>MIMAT0000064_st</th>\n",
       "      <th>MIMAT0000065_st</th>\n",
       "      <th>MIMAT0000066_st</th>\n",
       "      <th>MIMAT0000067_st</th>\n",
       "      <th>MIMAT0000068_st</th>\n",
       "      <th>MIMAT0000069_st</th>\n",
       "      <th>...</th>\n",
       "      <th>MIMAT0031119_st</th>\n",
       "      <th>MIMAT0031120_st</th>\n",
       "      <th>MIMAT0031175_st</th>\n",
       "      <th>MIMAT0031176_st</th>\n",
       "      <th>MIMAT0031177_st</th>\n",
       "      <th>MIMAT0031178_st</th>\n",
       "      <th>MIMAT0031179_st</th>\n",
       "      <th>MIMAT0031180_st</th>\n",
       "      <th>MIMAT0031181_st</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSM2278612</td>\n",
       "      <td>PDAC</td>\n",
       "      <td>1.129491</td>\n",
       "      <td>5.508052</td>\n",
       "      <td>2.923399</td>\n",
       "      <td>1.751963</td>\n",
       "      <td>0.693354</td>\n",
       "      <td>0.750790</td>\n",
       "      <td>0.685247</td>\n",
       "      <td>5.234038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913821</td>\n",
       "      <td>0.660219</td>\n",
       "      <td>0.484359</td>\n",
       "      <td>0.954552</td>\n",
       "      <td>1.271430</td>\n",
       "      <td>1.405966</td>\n",
       "      <td>0.597030</td>\n",
       "      <td>0.935637</td>\n",
       "      <td>0.930258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSM2278613</td>\n",
       "      <td>PDAC</td>\n",
       "      <td>1.727870</td>\n",
       "      <td>7.021726</td>\n",
       "      <td>4.075586</td>\n",
       "      <td>1.692451</td>\n",
       "      <td>0.748297</td>\n",
       "      <td>0.819648</td>\n",
       "      <td>1.228891</td>\n",
       "      <td>3.863134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572489</td>\n",
       "      <td>0.288395</td>\n",
       "      <td>0.911395</td>\n",
       "      <td>0.865855</td>\n",
       "      <td>1.191414</td>\n",
       "      <td>1.248563</td>\n",
       "      <td>0.880128</td>\n",
       "      <td>0.443996</td>\n",
       "      <td>0.461034</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSM2278614</td>\n",
       "      <td>PDAC</td>\n",
       "      <td>1.275866</td>\n",
       "      <td>5.847073</td>\n",
       "      <td>4.037849</td>\n",
       "      <td>1.675842</td>\n",
       "      <td>0.792464</td>\n",
       "      <td>0.854456</td>\n",
       "      <td>0.427473</td>\n",
       "      <td>5.030710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567179</td>\n",
       "      <td>0.585677</td>\n",
       "      <td>0.968250</td>\n",
       "      <td>0.416603</td>\n",
       "      <td>0.906936</td>\n",
       "      <td>0.515170</td>\n",
       "      <td>0.373492</td>\n",
       "      <td>1.029657</td>\n",
       "      <td>0.783717</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSM2278615</td>\n",
       "      <td>PDAC</td>\n",
       "      <td>1.231164</td>\n",
       "      <td>5.372768</td>\n",
       "      <td>3.634441</td>\n",
       "      <td>1.629729</td>\n",
       "      <td>0.835388</td>\n",
       "      <td>0.508545</td>\n",
       "      <td>0.633179</td>\n",
       "      <td>4.395977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606826</td>\n",
       "      <td>0.616086</td>\n",
       "      <td>0.910045</td>\n",
       "      <td>0.485816</td>\n",
       "      <td>0.481710</td>\n",
       "      <td>0.658906</td>\n",
       "      <td>0.486607</td>\n",
       "      <td>1.092210</td>\n",
       "      <td>0.877583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSM2278616</td>\n",
       "      <td>PDAC</td>\n",
       "      <td>1.598425</td>\n",
       "      <td>5.448495</td>\n",
       "      <td>3.763625</td>\n",
       "      <td>1.970805</td>\n",
       "      <td>0.652223</td>\n",
       "      <td>0.442908</td>\n",
       "      <td>0.477028</td>\n",
       "      <td>4.051217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798609</td>\n",
       "      <td>0.780584</td>\n",
       "      <td>0.655019</td>\n",
       "      <td>0.591214</td>\n",
       "      <td>1.120507</td>\n",
       "      <td>1.493095</td>\n",
       "      <td>0.723840</td>\n",
       "      <td>0.936191</td>\n",
       "      <td>0.714010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>GSM2278758</td>\n",
       "      <td>Controle</td>\n",
       "      <td>1.072158</td>\n",
       "      <td>6.132864</td>\n",
       "      <td>4.303285</td>\n",
       "      <td>1.466693</td>\n",
       "      <td>1.066174</td>\n",
       "      <td>0.743631</td>\n",
       "      <td>0.542135</td>\n",
       "      <td>4.761716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565492</td>\n",
       "      <td>0.494150</td>\n",
       "      <td>0.605459</td>\n",
       "      <td>0.665845</td>\n",
       "      <td>1.061685</td>\n",
       "      <td>0.433729</td>\n",
       "      <td>0.351924</td>\n",
       "      <td>0.844252</td>\n",
       "      <td>0.267246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>GSM2278759</td>\n",
       "      <td>Controle</td>\n",
       "      <td>1.688142</td>\n",
       "      <td>5.986205</td>\n",
       "      <td>3.848825</td>\n",
       "      <td>2.162682</td>\n",
       "      <td>0.984778</td>\n",
       "      <td>0.885241</td>\n",
       "      <td>0.934689</td>\n",
       "      <td>4.002943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829502</td>\n",
       "      <td>0.562959</td>\n",
       "      <td>1.029765</td>\n",
       "      <td>0.616121</td>\n",
       "      <td>0.528186</td>\n",
       "      <td>1.066021</td>\n",
       "      <td>0.886998</td>\n",
       "      <td>0.823196</td>\n",
       "      <td>0.621138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>GSM2278760</td>\n",
       "      <td>Controle</td>\n",
       "      <td>1.507370</td>\n",
       "      <td>5.871728</td>\n",
       "      <td>3.430393</td>\n",
       "      <td>1.897419</td>\n",
       "      <td>0.627474</td>\n",
       "      <td>0.908978</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>4.791717</td>\n",
       "      <td>...</td>\n",
       "      <td>1.177363</td>\n",
       "      <td>0.819254</td>\n",
       "      <td>0.368961</td>\n",
       "      <td>0.541980</td>\n",
       "      <td>1.179273</td>\n",
       "      <td>0.513666</td>\n",
       "      <td>0.789142</td>\n",
       "      <td>1.221342</td>\n",
       "      <td>0.959684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>GSM2278761</td>\n",
       "      <td>Controle</td>\n",
       "      <td>0.588391</td>\n",
       "      <td>6.057384</td>\n",
       "      <td>4.142099</td>\n",
       "      <td>1.870668</td>\n",
       "      <td>1.081216</td>\n",
       "      <td>0.611892</td>\n",
       "      <td>0.771683</td>\n",
       "      <td>5.097688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604917</td>\n",
       "      <td>0.446808</td>\n",
       "      <td>0.563384</td>\n",
       "      <td>0.238049</td>\n",
       "      <td>0.932333</td>\n",
       "      <td>0.753658</td>\n",
       "      <td>0.141102</td>\n",
       "      <td>1.277319</td>\n",
       "      <td>0.443357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>GSM2278762</td>\n",
       "      <td>Controle</td>\n",
       "      <td>2.190063</td>\n",
       "      <td>6.569068</td>\n",
       "      <td>4.312643</td>\n",
       "      <td>2.956169</td>\n",
       "      <td>0.847391</td>\n",
       "      <td>0.428441</td>\n",
       "      <td>0.902588</td>\n",
       "      <td>4.800067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.540816</td>\n",
       "      <td>0.588735</td>\n",
       "      <td>0.786975</td>\n",
       "      <td>1.061247</td>\n",
       "      <td>0.775727</td>\n",
       "      <td>0.621713</td>\n",
       "      <td>0.508141</td>\n",
       "      <td>1.150417</td>\n",
       "      <td>0.653498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows √ó 2581 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID     Grupo  MIMAT0000062_st  MIMAT0000063_st  MIMAT0000064_st  \\\n",
       "0    GSM2278612      PDAC         1.129491         5.508052         2.923399   \n",
       "1    GSM2278613      PDAC         1.727870         7.021726         4.075586   \n",
       "2    GSM2278614      PDAC         1.275866         5.847073         4.037849   \n",
       "3    GSM2278615      PDAC         1.231164         5.372768         3.634441   \n",
       "4    GSM2278616      PDAC         1.598425         5.448495         3.763625   \n",
       "..          ...       ...              ...              ...              ...   \n",
       "102  GSM2278758  Controle         1.072158         6.132864         4.303285   \n",
       "103  GSM2278759  Controle         1.688142         5.986205         3.848825   \n",
       "104  GSM2278760  Controle         1.507370         5.871728         3.430393   \n",
       "105  GSM2278761  Controle         0.588391         6.057384         4.142099   \n",
       "106  GSM2278762  Controle         2.190063         6.569068         4.312643   \n",
       "\n",
       "     MIMAT0000065_st  MIMAT0000066_st  MIMAT0000067_st  MIMAT0000068_st  \\\n",
       "0           1.751963         0.693354         0.750790         0.685247   \n",
       "1           1.692451         0.748297         0.819648         1.228891   \n",
       "2           1.675842         0.792464         0.854456         0.427473   \n",
       "3           1.629729         0.835388         0.508545         0.633179   \n",
       "4           1.970805         0.652223         0.442908         0.477028   \n",
       "..               ...              ...              ...              ...   \n",
       "102         1.466693         1.066174         0.743631         0.542135   \n",
       "103         2.162682         0.984778         0.885241         0.934689   \n",
       "104         1.897419         0.627474         0.908978         0.458824   \n",
       "105         1.870668         1.081216         0.611892         0.771683   \n",
       "106         2.956169         0.847391         0.428441         0.902588   \n",
       "\n",
       "     MIMAT0000069_st  ...  MIMAT0031119_st  MIMAT0031120_st  MIMAT0031175_st  \\\n",
       "0           5.234038  ...         0.913821         0.660219         0.484359   \n",
       "1           3.863134  ...         0.572489         0.288395         0.911395   \n",
       "2           5.030710  ...         0.567179         0.585677         0.968250   \n",
       "3           4.395977  ...         0.606826         0.616086         0.910045   \n",
       "4           4.051217  ...         0.798609         0.780584         0.655019   \n",
       "..               ...  ...              ...              ...              ...   \n",
       "102         4.761716  ...         0.565492         0.494150         0.605459   \n",
       "103         4.002943  ...         0.829502         0.562959         1.029765   \n",
       "104         4.791717  ...         1.177363         0.819254         0.368961   \n",
       "105         5.097688  ...         0.604917         0.446808         0.563384   \n",
       "106         4.800067  ...         0.540816         0.588735         0.786975   \n",
       "\n",
       "     MIMAT0031176_st  MIMAT0031177_st  MIMAT0031178_st  MIMAT0031179_st  \\\n",
       "0           0.954552         1.271430         1.405966         0.597030   \n",
       "1           0.865855         1.191414         1.248563         0.880128   \n",
       "2           0.416603         0.906936         0.515170         0.373492   \n",
       "3           0.485816         0.481710         0.658906         0.486607   \n",
       "4           0.591214         1.120507         1.493095         0.723840   \n",
       "..               ...              ...              ...              ...   \n",
       "102         0.665845         1.061685         0.433729         0.351924   \n",
       "103         0.616121         0.528186         1.066021         0.886998   \n",
       "104         0.541980         1.179273         0.513666         0.789142   \n",
       "105         0.238049         0.932333         0.753658         0.141102   \n",
       "106         1.061247         0.775727         0.621713         0.508141   \n",
       "\n",
       "     MIMAT0031180_st  MIMAT0031181_st  y  \n",
       "0           0.935637         0.930258  1  \n",
       "1           0.443996         0.461034  1  \n",
       "2           1.029657         0.783717  1  \n",
       "3           1.092210         0.877583  1  \n",
       "4           0.936191         0.714010  1  \n",
       "..               ...              ... ..  \n",
       "102         0.844252         0.267246  0  \n",
       "103         0.823196         0.621138  0  \n",
       "104         1.221342         0.959684  0  \n",
       "105         1.277319         0.443357  0  \n",
       "106         1.150417         0.653498  0  \n",
       "\n",
       "[107 rows x 2581 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from joblib import dump, load\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, cross_validate\n",
    "from collections import Counter\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pprint import pprint\n",
    "import random\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dados = pd.read_csv (\"Databases/PDACCTRL_samplesXfeatures_RAW.csv\", sep=',')\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c36594bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MIMAT0000062_st</th>\n",
       "      <th>MIMAT0000063_st</th>\n",
       "      <th>MIMAT0000064_st</th>\n",
       "      <th>MIMAT0000065_st</th>\n",
       "      <th>MIMAT0000066_st</th>\n",
       "      <th>MIMAT0000067_st</th>\n",
       "      <th>MIMAT0000068_st</th>\n",
       "      <th>MIMAT0000069_st</th>\n",
       "      <th>MIMAT0000070_st</th>\n",
       "      <th>MIMAT0000071_st</th>\n",
       "      <th>...</th>\n",
       "      <th>MIMAT0031175_st</th>\n",
       "      <th>MIMAT0031176_st</th>\n",
       "      <th>MIMAT0031177_st</th>\n",
       "      <th>MIMAT0031178_st</th>\n",
       "      <th>MIMAT0031179_st</th>\n",
       "      <th>MIMAT0031180_st</th>\n",
       "      <th>MIMAT0031181_st</th>\n",
       "      <th>Grupo_Controle</th>\n",
       "      <th>Grupo_PDAC</th>\n",
       "      <th>Grupo_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.364020</td>\n",
       "      <td>0.616390</td>\n",
       "      <td>0.295100</td>\n",
       "      <td>0.357728</td>\n",
       "      <td>0.346143</td>\n",
       "      <td>0.246612</td>\n",
       "      <td>0.281153</td>\n",
       "      <td>0.791741</td>\n",
       "      <td>0.567829</td>\n",
       "      <td>0.293147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318945</td>\n",
       "      <td>0.485705</td>\n",
       "      <td>0.572516</td>\n",
       "      <td>0.820679</td>\n",
       "      <td>0.450881</td>\n",
       "      <td>0.418451</td>\n",
       "      <td>0.829685</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.566594</td>\n",
       "      <td>0.930115</td>\n",
       "      <td>0.621546</td>\n",
       "      <td>0.339320</td>\n",
       "      <td>0.389451</td>\n",
       "      <td>0.274622</td>\n",
       "      <td>0.596963</td>\n",
       "      <td>0.371203</td>\n",
       "      <td>0.940650</td>\n",
       "      <td>0.244754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753015</td>\n",
       "      <td>0.430443</td>\n",
       "      <td>0.524971</td>\n",
       "      <td>0.710573</td>\n",
       "      <td>0.730846</td>\n",
       "      <td>0.132892</td>\n",
       "      <td>0.395607</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.413573</td>\n",
       "      <td>0.686656</td>\n",
       "      <td>0.610854</td>\n",
       "      <td>0.334182</td>\n",
       "      <td>0.424265</td>\n",
       "      <td>0.288782</td>\n",
       "      <td>0.131408</td>\n",
       "      <td>0.729368</td>\n",
       "      <td>0.610426</td>\n",
       "      <td>0.575846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810807</td>\n",
       "      <td>0.150539</td>\n",
       "      <td>0.355937</td>\n",
       "      <td>0.197553</td>\n",
       "      <td>0.229818</td>\n",
       "      <td>0.473060</td>\n",
       "      <td>0.694120</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.398440</td>\n",
       "      <td>0.588351</td>\n",
       "      <td>0.496557</td>\n",
       "      <td>0.319919</td>\n",
       "      <td>0.458100</td>\n",
       "      <td>0.148070</td>\n",
       "      <td>0.250906</td>\n",
       "      <td>0.534658</td>\n",
       "      <td>0.831239</td>\n",
       "      <td>0.250591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751642</td>\n",
       "      <td>0.193662</td>\n",
       "      <td>0.103271</td>\n",
       "      <td>0.298098</td>\n",
       "      <td>0.341681</td>\n",
       "      <td>0.509392</td>\n",
       "      <td>0.780955</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.522772</td>\n",
       "      <td>0.604046</td>\n",
       "      <td>0.533159</td>\n",
       "      <td>0.425419</td>\n",
       "      <td>0.313721</td>\n",
       "      <td>0.121369</td>\n",
       "      <td>0.160196</td>\n",
       "      <td>0.428900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.237128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492416</td>\n",
       "      <td>0.259330</td>\n",
       "      <td>0.482838</td>\n",
       "      <td>0.881627</td>\n",
       "      <td>0.576288</td>\n",
       "      <td>0.418772</td>\n",
       "      <td>0.629635</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.344610</td>\n",
       "      <td>0.745889</td>\n",
       "      <td>0.686059</td>\n",
       "      <td>0.269489</td>\n",
       "      <td>0.640015</td>\n",
       "      <td>0.243700</td>\n",
       "      <td>0.198017</td>\n",
       "      <td>0.646852</td>\n",
       "      <td>0.622801</td>\n",
       "      <td>0.311664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442040</td>\n",
       "      <td>0.305828</td>\n",
       "      <td>0.447887</td>\n",
       "      <td>0.140583</td>\n",
       "      <td>0.208489</td>\n",
       "      <td>0.365372</td>\n",
       "      <td>0.216334</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.553144</td>\n",
       "      <td>0.715492</td>\n",
       "      <td>0.557298</td>\n",
       "      <td>0.484770</td>\n",
       "      <td>0.575855</td>\n",
       "      <td>0.301305</td>\n",
       "      <td>0.426057</td>\n",
       "      <td>0.414091</td>\n",
       "      <td>0.457515</td>\n",
       "      <td>0.127880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873334</td>\n",
       "      <td>0.274848</td>\n",
       "      <td>0.130887</td>\n",
       "      <td>0.582882</td>\n",
       "      <td>0.737640</td>\n",
       "      <td>0.353141</td>\n",
       "      <td>0.543719</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.491946</td>\n",
       "      <td>0.691766</td>\n",
       "      <td>0.438745</td>\n",
       "      <td>0.402720</td>\n",
       "      <td>0.294213</td>\n",
       "      <td>0.310961</td>\n",
       "      <td>0.149621</td>\n",
       "      <td>0.656055</td>\n",
       "      <td>0.669959</td>\n",
       "      <td>0.330950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201646</td>\n",
       "      <td>0.228655</td>\n",
       "      <td>0.517757</td>\n",
       "      <td>0.196500</td>\n",
       "      <td>0.640867</td>\n",
       "      <td>0.584396</td>\n",
       "      <td>0.856907</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.180837</td>\n",
       "      <td>0.730245</td>\n",
       "      <td>0.640391</td>\n",
       "      <td>0.394445</td>\n",
       "      <td>0.651872</td>\n",
       "      <td>0.190110</td>\n",
       "      <td>0.331365</td>\n",
       "      <td>0.749914</td>\n",
       "      <td>0.581655</td>\n",
       "      <td>0.119255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399272</td>\n",
       "      <td>0.039293</td>\n",
       "      <td>0.371028</td>\n",
       "      <td>0.364379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616909</td>\n",
       "      <td>0.379254</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.723064</td>\n",
       "      <td>0.836297</td>\n",
       "      <td>0.688710</td>\n",
       "      <td>0.730210</td>\n",
       "      <td>0.467561</td>\n",
       "      <td>0.115484</td>\n",
       "      <td>0.407409</td>\n",
       "      <td>0.658616</td>\n",
       "      <td>0.288229</td>\n",
       "      <td>0.571324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626546</td>\n",
       "      <td>0.552181</td>\n",
       "      <td>0.277974</td>\n",
       "      <td>0.272081</td>\n",
       "      <td>0.362976</td>\n",
       "      <td>0.543201</td>\n",
       "      <td>0.573654</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows √ó 2581 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MIMAT0000062_st  MIMAT0000063_st  MIMAT0000064_st  MIMAT0000065_st  \\\n",
       "0           0.364020         0.616390         0.295100         0.357728   \n",
       "1           0.566594         0.930115         0.621546         0.339320   \n",
       "2           0.413573         0.686656         0.610854         0.334182   \n",
       "3           0.398440         0.588351         0.496557         0.319919   \n",
       "4           0.522772         0.604046         0.533159         0.425419   \n",
       "..               ...              ...              ...              ...   \n",
       "102         0.344610         0.745889         0.686059         0.269489   \n",
       "103         0.553144         0.715492         0.557298         0.484770   \n",
       "104         0.491946         0.691766         0.438745         0.402720   \n",
       "105         0.180837         0.730245         0.640391         0.394445   \n",
       "106         0.723064         0.836297         0.688710         0.730210   \n",
       "\n",
       "     MIMAT0000066_st  MIMAT0000067_st  MIMAT0000068_st  MIMAT0000069_st  \\\n",
       "0           0.346143         0.246612         0.281153         0.791741   \n",
       "1           0.389451         0.274622         0.596963         0.371203   \n",
       "2           0.424265         0.288782         0.131408         0.729368   \n",
       "3           0.458100         0.148070         0.250906         0.534658   \n",
       "4           0.313721         0.121369         0.160196         0.428900   \n",
       "..               ...              ...              ...              ...   \n",
       "102         0.640015         0.243700         0.198017         0.646852   \n",
       "103         0.575855         0.301305         0.426057         0.414091   \n",
       "104         0.294213         0.310961         0.149621         0.656055   \n",
       "105         0.651872         0.190110         0.331365         0.749914   \n",
       "106         0.467561         0.115484         0.407409         0.658616   \n",
       "\n",
       "     MIMAT0000070_st  MIMAT0000071_st  ...  MIMAT0031175_st  MIMAT0031176_st  \\\n",
       "0           0.567829         0.293147  ...         0.318945         0.485705   \n",
       "1           0.940650         0.244754  ...         0.753015         0.430443   \n",
       "2           0.610426         0.575846  ...         0.810807         0.150539   \n",
       "3           0.831239         0.250591  ...         0.751642         0.193662   \n",
       "4           1.000000         0.237128  ...         0.492416         0.259330   \n",
       "..               ...              ...  ...              ...              ...   \n",
       "102         0.622801         0.311664  ...         0.442040         0.305828   \n",
       "103         0.457515         0.127880  ...         0.873334         0.274848   \n",
       "104         0.669959         0.330950  ...         0.201646         0.228655   \n",
       "105         0.581655         0.119255  ...         0.399272         0.039293   \n",
       "106         0.288229         0.571324  ...         0.626546         0.552181   \n",
       "\n",
       "     MIMAT0031177_st  MIMAT0031178_st  MIMAT0031179_st  MIMAT0031180_st  \\\n",
       "0           0.572516         0.820679         0.450881         0.418451   \n",
       "1           0.524971         0.710573         0.730846         0.132892   \n",
       "2           0.355937         0.197553         0.229818         0.473060   \n",
       "3           0.103271         0.298098         0.341681         0.509392   \n",
       "4           0.482838         0.881627         0.576288         0.418772   \n",
       "..               ...              ...              ...              ...   \n",
       "102         0.447887         0.140583         0.208489         0.365372   \n",
       "103         0.130887         0.582882         0.737640         0.353141   \n",
       "104         0.517757         0.196500         0.640867         0.584396   \n",
       "105         0.371028         0.364379         0.000000         0.616909   \n",
       "106         0.277974         0.272081         0.362976         0.543201   \n",
       "\n",
       "     MIMAT0031181_st  Grupo_Controle  Grupo_PDAC  Grupo_nan  \n",
       "0           0.829685               0           1          0  \n",
       "1           0.395607               0           1          0  \n",
       "2           0.694120               0           1          0  \n",
       "3           0.780955               0           1          0  \n",
       "4           0.629635               0           1          0  \n",
       "..               ...             ...         ...        ...  \n",
       "102         0.216334               1           0          0  \n",
       "103         0.543719               1           0          0  \n",
       "104         0.856907               1           0          0  \n",
       "105         0.379254               1           0          0  \n",
       "106         0.573654               1           0          0  \n",
       "\n",
       "[107 rows x 2581 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalizar\n",
    "dados_num = dados.drop(columns=[\"Sample_ID\", \"Grupo\", \"y\"])\n",
    "dados_cat =dados[[\"Grupo\"]]\n",
    "\n",
    "#Instaciar o objeto normalizador\n",
    "normalizador = preprocessing.MinMaxScaler()\n",
    "#treinar o modelo normalizador\n",
    "modelo_normalizador_num = normalizador.fit(dados_num)\n",
    "#Salvando modelo normalizador para uso posterior\n",
    "os.makedirs('models_Tree', exist_ok=True)\n",
    "dump(modelo_normalizador_num, open(\"models_Tree/normalizador_TCC_Tree.model\" , \"wb\" ))\n",
    "\n",
    "#normalizar os atributos numericos\n",
    "dados_num_normalizado = modelo_normalizador_num.transform(dados_num)\n",
    "# Normalizar os dados Categoricos\n",
    "dados_cat_normalizado = pd.get_dummies(dados_cat, dtype='int', dummy_na=True)\n",
    "# Converter dados num√©ricos normalizados para DataFrame\n",
    "dados_num_df = pd.DataFrame(dados_num_normalizado, columns=dados_num.columns)\n",
    "# unir atributos num e cat que foram normalizados\n",
    "dados_final = dados_num_df.join(dados_cat_normalizado)\n",
    "dados_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad0dbf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dados_processados shape: (107, 2578)\n",
      "Tipos de nomes de colunas: [<class 'str'>]\n",
      "N√∫mero de colunas duplicadas: 0\n",
      "Alguma coluna com nome vazio ou NaN? False\n",
      "Total NaNs restantes: 0\n",
      "Exemplo das primeiras colunas de dados_processados:\n",
      "   MIMAT0000062_st  MIMAT0000063_st  MIMAT0000064_st  MIMAT0000065_st  \\\n",
      "0         0.364020         0.616390         0.295100         0.357728   \n",
      "1         0.566594         0.930115         0.621546         0.339320   \n",
      "2         0.413573         0.686656         0.610854         0.334182   \n",
      "3         0.398440         0.588351         0.496557         0.319919   \n",
      "4         0.522772         0.604046         0.533159         0.425419   \n",
      "\n",
      "   MIMAT0000066_st  MIMAT0000067_st  MIMAT0000068_st  MIMAT0000069_st  \\\n",
      "0         0.346143         0.246612         0.281153         0.791741   \n",
      "1         0.389451         0.274622         0.596963         0.371203   \n",
      "2         0.424265         0.288782         0.131408         0.729368   \n",
      "3         0.458100         0.148070         0.250906         0.534658   \n",
      "4         0.313721         0.121369         0.160196         0.428900   \n",
      "\n",
      "   MIMAT0000070_st  MIMAT0000071_st  \n",
      "0         0.567829         0.293147  \n",
      "1         0.940650         0.244754  \n",
      "2         0.610426         0.575846  \n",
      "3         0.831239         0.250591  \n",
      "4         1.000000         0.237128  \n",
      "Colunas originais em dados_classes: ['Grupo_Controle', 'Grupo_PDAC']\n",
      "Duplicadas em dados_classes?: [False, False]\n",
      "#### FREQU√äNCIA DAS CLASSES AP√ìS O BALANCEAMENTO ####\n",
      "Counter({1: 88, 0: 88})\n",
      "#### FREQU√äNCIA DAS CLASSES AP√ìS O BALANCEAMENTO ####\n",
      "Counter({1: 88, 0: 88})\n"
     ]
    }
   ],
   "source": [
    "dados_filtered = dados_final.drop(columns=['Grupo_nan'])\n",
    "\n",
    "# Segmentar os dados em atributos e classes\n",
    "dados_classes = dados_filtered[['Grupo_Controle', 'Grupo_PDAC']]\n",
    "dados_atributos = dados_filtered.drop(columns=['Grupo_Controle', 'Grupo_PDAC'])\n",
    "\n",
    "# Preprocessamento\n",
    "# Tratar colunas categ√≥ricas (corrigido: aplicar get_dummies NOS VALORES, n√£o no Index)\n",
    "cols_cat = dados_atributos.select_dtypes(include=['object']).columns\n",
    "if len(cols_cat) > 0:\n",
    "    dados_cat_normalizado = pd.get_dummies(dados_atributos[cols_cat], dtype='int', dummy_na=True)\n",
    "else:\n",
    "    dados_cat_normalizado = pd.DataFrame(index=dados_atributos.index)\n",
    "\n",
    "# Tratar colunas num√©ricas\n",
    "dados_num = dados_atributos.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Preencher NaNs num√©ricos com a m√©dia da coluna\n",
    "dados_num_preenchido = dados_atributos[dados_num].fillna(dados_atributos[dados_num].mean())\n",
    "\n",
    "# Juntar num√©ricos preenchidos e categ√≥ricos dummificados (garantindo mesmo √≠ndice)\n",
    "dados_num_preenchido = dados_num_preenchido.reset_index(drop=True) # teste\n",
    "dados_cat_normalizado = dados_cat_normalizado.reset_index(drop=True)# teste\n",
    "dados_processados = pd.concat([dados_num_preenchido, dados_cat_normalizado], axis=1)\n",
    "\n",
    "# Garantir que todos os nomes de coluna sejam strings (requisito do sklearn/imblearn)\n",
    "dados_processados.columns = dados_processados.columns.astype(str)\n",
    "\n",
    "# Imputa√ß√£o: preencher NaNs nas colunas num√©ricas com a m√©dia; preencher o restante com 0\n",
    "dados_processados = dados_processados.copy()\n",
    "num_cols = dados_processados.select_dtypes(include=[np.number]).columns\n",
    "if len(num_cols) > 0:\n",
    "    dados_processados[num_cols] = dados_processados[num_cols].fillna(dados_processados[num_cols].mean())\n",
    "# preencher quaisquer NaNs restantes (por exemplo, nas colunas dummies) com 0\n",
    "dados_processados = dados_processados.fillna(0)\n",
    "\n",
    "# Verifica√ß√µes r√°pidas\n",
    "print('dados_processados shape:', dados_processados.shape)\n",
    "print('Tipos de nomes de colunas:', pd.Series(dados_processados.columns).apply(type).unique())\n",
    "dups = pd.Index(dados_processados.columns).duplicated().sum()\n",
    "print('N√∫mero de colunas duplicadas:', dups)\n",
    "print('Alguma coluna com nome vazio ou NaN?', any([c == '' or pd.isna(c) for c in dados_processados.columns]))\n",
    "print('Total NaNs restantes:', dados_processados.isna().sum().sum())\n",
    "print('Exemplo das primeiras colunas de dados_processados:')\n",
    "print(dados_processados.iloc[:5, :10])\n",
    "# Verifica√ß√£o das colunas de classe (ajuda a diagnosticar nomes duplicados)\n",
    "print('Colunas originais em dados_classes:', list(dados_classes.columns))\n",
    "print('Duplicadas em dados_classes?:', dados_classes.columns.duplicated().tolist())\n",
    "\n",
    "# Criar uma coluna de classe unificada (1 = PDAC, 0 = Controle)\n",
    "# Isso transforma o DataFrame de 2 colunas em uma √∫nica Series bin√°ria\n",
    "dados_classes_bin = np.where(dados_classes['Grupo_PDAC'] == 1, 1, 0)\n",
    "\n",
    "# Construir o objeto SMOTE e executar o fit_resample\n",
    "resampler = SMOTE(random_state=42)\n",
    "dados_atributos_b, dados_classes_b = resampler.fit_resample(dados_processados, dados_classes_bin)\n",
    "\n",
    "# Verificar a frequ√™ncia das classes balanceadas\n",
    "print('#### FREQU√äNCIA DAS CLASSES AP√ìS O BALANCEAMENTO ####')\n",
    "print(Counter(dados_classes_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8d5424c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In√≠cio do balanceamento\n",
      "\n",
      "Balanceando para a classe: 'Grupo_Controle'\n",
      "Distribui√ß√£o das classes ap√≥s balanceamento:\n",
      "Counter({0: 88, 1: 88})\n",
      "\n",
      "Balanceando para a classe: 'Grupo_PDAC'\n",
      "Distribui√ß√£o das classes ap√≥s balanceamento:\n",
      "Counter({1: 88, 0: 88})\n",
      "Distribui√ß√£o das classes ap√≥s balanceamento:\n",
      "Counter({0: 88, 1: 88})\n",
      "\n",
      "Balanceando para a classe: 'Grupo_PDAC'\n",
      "Distribui√ß√£o das classes ap√≥s balanceamento:\n",
      "Counter({1: 88, 0: 88})\n"
     ]
    }
   ],
   "source": [
    "# Dicionario para armazenar os dados balanceados das classes\n",
    "dados_balanceados = {}\n",
    "\n",
    "print(\"In√≠cio do balanceamento\")\n",
    "\n",
    "# Loop para balancear cada classe (3x)\n",
    "for classe in dados_classes.columns:\n",
    "    print(f\"\\nBalanceando para a classe: '{classe}'\")\n",
    "\n",
    "    # Criar vetor binario para a classe atual: 1 se for essa classe, 0 caso contr√°rio\n",
    "    y_bin = dados_classes[classe]\n",
    "\n",
    "    # Instanciar SMOTE com random_state para reprodutibilidade\n",
    "    smote = SMOTE(random_state=42)\n",
    "\n",
    "    # Aplicar o balanceamento com SMOTE\n",
    "    X_res, y_res = smote.fit_resample(dados_processados, y_bin)\n",
    "\n",
    "    # Exibir a contagem das classes ap√≥s balanceamento\n",
    "    print(\"Distribui√ß√£o das classes ap√≥s balanceamento:\")\n",
    "    print(Counter(y_res))\n",
    "\n",
    "    # Armazenar os dados balanceados para essa classe\n",
    "    dados_balanceados[classe] = (X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f5b50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar cada classe balanceada\n",
    "for classe, (X, y) in dados_balanceados.items():\n",
    "    print(f\"\\nTreinando modelo para a classe: '{classe}'\")\n",
    "\n",
    "    # HOLD OUT (70-30)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    # Determinar os HIPERPARAMETROS\n",
    "    # Ampliar o espa√ßo de busca para max_depth e aumentar n_iter para explorar mais combina√ß√µes\n",
    "    tree_grid = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 5, 10, 20, 30, 50, 100],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "    tree_hyperparameters = RandomizedSearchCV(tree, param_distributions=tree_grid, n_iter=50, cv=10, verbose=2, random_state=42, n_jobs=-1)\n",
    "    tree_hyperparameters.fit(X_train, y_train)\n",
    "    best_params = tree_hyperparameters.best_params_\n",
    "    pprint(f\"Melhores parametros para '{classe}': {best_params}\")\n",
    "\n",
    "    # Treinar o modelo com os melhores hiperparametros\n",
    "    tree = DecisionTreeClassifier(**best_params, random_state=42)\n",
    "    tree.fit(X, y)\n",
    "\n",
    "    # Avaliar a acuracia do modelo com Cross Validation\n",
    "    scores = cross_val_score(tree, X, y, cv=10, scoring='accuracy')\n",
    "    print(f\"Acur√°cia m√©dia para '{classe}': {scores.mean():.4f}\")\n",
    "    print(f\"Acur√°cias individuais: {scores}\")\n",
    "\n",
    "    # Salvar modelo\n",
    "    pasta_modelos = os.path.join(os.getcwd(), 'models_Tree')\n",
    "    os.makedirs(pasta_modelos, exist_ok=True)\n",
    "\n",
    "    nome_arquivo = f\"modelo_{classe.replace(' ', '_')}.joblib\"\n",
    "    caminho_arquivo = os.path.join(pasta_modelos, nome_arquivo)\n",
    "    dump(tree, caminho_arquivo)\n",
    "\n",
    "    print(f\"### Modelo salvo em: {caminho_arquivo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa31c611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Treinando modelo para a classe: 'Grupo_Controle'\n",
      "Fitting 10 folds for each of 150 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 52\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# ==========================\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Busca aleat√≥ria ampliada\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# ==========================\u001b[39;00m\n\u001b[0;32m     42\u001b[0m rf_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m     43\u001b[0m     rf,\n\u001b[0;32m     44\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mrf_grid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     50\u001b[0m )\n\u001b[1;32m---> 52\u001b[0m \u001b[43mrf_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m best_params \u001b[38;5;241m=\u001b[39m rf_search\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[0;32m     54\u001b[0m pprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Melhores par√¢metros para \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\cassi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cassi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\cassi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1960\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1962\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1963\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cassi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\cassi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cassi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cassi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cassi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from joblib import dump\n",
    "\n",
    "# ================================================\n",
    "# Treinamento para cada classe balanceada\n",
    "# ================================================\n",
    "for classe, (X, y) in dados_balanceados.items():\n",
    "    print(f\"\\nüîπ Treinando modelo para a classe: '{classe}'\")\n",
    "\n",
    "    # HOLD OUT (70-30)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # ==========================\n",
    "    # Instanciar modelo base\n",
    "    # ==========================\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # ==========================\n",
    "    # Hiperpar√¢metros a testar\n",
    "    # ==========================\n",
    "    rf_grid = {\n",
    "        'n_estimators': [200, 500, 800, 1000],\n",
    "        'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "        'max_depth': [None, 10, 20, 30, 50, 100],\n",
    "        'min_samples_split': [2, 5, 10, 20],\n",
    "        'min_samples_leaf': [1, 2, 4, 8],\n",
    "        'max_features': ['sqrt', 'log2', None],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    }\n",
    "\n",
    "    # ==========================\n",
    "    # Busca aleat√≥ria ampliada\n",
    "    # ==========================\n",
    "    rf_search = RandomizedSearchCV(\n",
    "        rf,\n",
    "        param_distributions=rf_grid,\n",
    "        n_iter=100,            # ‚Üë aumenta o tempo e a qualidade\n",
    "        cv=10,\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    rf_search.fit(X_train, y_train)\n",
    "    best_params = rf_search.best_params_\n",
    "    pprint(f\"‚úÖ Melhores par√¢metros para '{classe}': {best_params}\")\n",
    "\n",
    "    # ==========================\n",
    "    # Treinar modelo final\n",
    "    # ==========================\n",
    "    best_rf = RandomForestClassifier(**best_params, random_state=42)\n",
    "    best_rf.fit(X, y)\n",
    "\n",
    "    # ==========================\n",
    "    # Avaliar desempenho\n",
    "    # ==========================\n",
    "    scores = cross_val_score(best_rf, X, y, cv=10, scoring='accuracy')\n",
    "    print(f\"Acur√°cia m√©dia para '{classe}': {scores.mean():.4f}\")\n",
    "    print(f\"Acur√°cias individuais: {scores}\")\n",
    "\n",
    "    # ==========================\n",
    "    # Salvar modelo\n",
    "    # ==========================\n",
    "    pasta_modelos = os.path.join(os.getcwd(), 'models_RF')\n",
    "    os.makedirs(pasta_modelos, exist_ok=True)\n",
    "\n",
    "    nome_arquivo = f\"modelo_{classe.replace(' ', '_')}.joblib\"\n",
    "    caminho_arquivo = os.path.join(pasta_modelos, nome_arquivo)\n",
    "    dump(best_rf, caminho_arquivo)\n",
    "\n",
    "    print(f\"üíæ Modelo salvo em: {caminho_arquivo}\")\n",
    "\n",
    "    # ================================================\n",
    "    # Import√¢ncia das features (miRNAs)\n",
    "    # ================================================\n",
    "    importancias = best_rf.feature_importances_\n",
    "    colunas = dados_processados.columns\n",
    "\n",
    "    importancia_df = pd.DataFrame({\n",
    "        'miRNA': colunas,\n",
    "        'Importancia': importancias\n",
    "    }).sort_values(by='Importancia', ascending=False)\n",
    "\n",
    "    print(\"\\nüîù Top 20 miRNAs mais importantes:\")\n",
    "    print(importancia_df.head(20))\n",
    "\n",
    "    # Contagem de features com import√¢ncia > 0\n",
    "    n_total = len(importancias)\n",
    "    n_nonzero = (importancias > 0).sum()\n",
    "    print(f\"\\nTotal de features: {n_total}, com import√¢ncia > 0: {n_nonzero}\")\n",
    "\n",
    "    # ================================================\n",
    "    # Diagn√≥stico da √°rvore / floresta\n",
    "    # ================================================\n",
    "    profundidades = [est.get_depth() for est in best_rf.estimators_]\n",
    "    folhas = [est.get_n_leaves() for est in best_rf.estimators_]\n",
    "\n",
    "    print(f\"\\nüå≥ Profundidade m√©dia das √°rvores: {np.mean(profundidades):.2f}\")\n",
    "    print(f\"üåø N√∫mero m√©dio de folhas: {np.mean(folhas):.2f}\")\n",
    "\n",
    "    # ================================================\n",
    "    # Estat√≠sticas das top features\n",
    "    # ================================================\n",
    "    variances = dados_processados.var()\n",
    "    unique_counts = dados_processados.nunique()\n",
    "\n",
    "    print('\\nTop 20 vari√¢ncias das features:')\n",
    "    print(variances.sort_values(ascending=False).head(20))\n",
    "\n",
    "    print('\\nUnique counts das top features importantes:')\n",
    "    for feat in importancia_df['miRNA'].head(10).values:\n",
    "        print(\n",
    "            feat,\n",
    "            '-> variance:', variances.get(feat, float('nan')),\n",
    "            'unique:', unique_counts.get(feat, float('nan')),\n",
    "            'min/max:', dados_processados[feat].min(), '/',\n",
    "            dados_processados[feat].max()\n",
    "        )\n",
    "\n",
    "    # ================================================\n",
    "    # Gr√°fico das top 20 import√¢ncias\n",
    "    # ================================================\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(\n",
    "        importancia_df['miRNA'].head(20)[::-1],\n",
    "        importancia_df['Importancia'].head(20)[::-1]\n",
    "    )\n",
    "    plt.xlabel('Import√¢ncia')\n",
    "    plt.ylabel('miRNA')\n",
    "    plt.title(f\"Top 20 miRNAs mais importantes - Classe '{classe}'\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nüß† Observa√ß√£o: RandomForest utiliza diversas √°rvores, \"\n",
    "          \"permitindo melhor generaliza√ß√£o e maior n√∫mero de miRNAs relevantes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93fcf0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinando RandomForest para: Grupo_Controle\n",
      "RF salvo em: c:\\Users\\cassi\\OneDrive\\Documentos\\1-Programas\\TCC\\models_Tree\\modelo_RF_Grupo_Controle.joblib\n",
      "Calculando permutation importance (pode demorar) ...\n",
      "RF salvo em: c:\\Users\\cassi\\OneDrive\\Documentos\\1-Programas\\TCC\\models_Tree\\modelo_RF_Grupo_Controle.joblib\n",
      "Calculando permutation importance (pode demorar) ...\n",
      "\n",
      "Top 20 (impurity)\n",
      "              feature  impurity_imp\n",
      "1351  MIMAT0019059_st      0.038749\n",
      "1481  MIMAT0019745_st      0.036633\n",
      "1249  MIMAT0018954_st      0.034090\n",
      "997   MIMAT0015086_st      0.032595\n",
      "1793  MIMAT0022264_st      0.024312\n",
      "2541  MIMAT0030991_st      0.023391\n",
      "357   MIMAT0003251_st      0.022597\n",
      "738   MIMAT0005829_st      0.019573\n",
      "939   MIMAT0015025_st      0.017911\n",
      "2561  MIMAT0031011_st      0.017806\n",
      "992   MIMAT0015081_st      0.014513\n",
      "1     MIMAT0000063_st      0.014118\n",
      "1545  MIMAT0019810_st      0.013611\n",
      "500   MIMAT0004518_st      0.013046\n",
      "614   MIMAT0004784_st      0.012881\n",
      "1100  MIMAT0017991_st      0.012714\n",
      "1218  MIMAT0018446_st      0.012221\n",
      "137   MIMAT0000646_st      0.011712\n",
      "1570  MIMAT0019835_st      0.010724\n",
      "2158  MIMAT0027392_st      0.010050\n",
      "\n",
      "Top 20 (permutation)\n",
      "MIMAT0019059_st    0.016981\n",
      "MIMAT0019977_st    0.000000\n",
      "MIMAT0019978_st    0.000000\n",
      "MIMAT0019979_st    0.000000\n",
      "MIMAT0019980_st    0.000000\n",
      "MIMAT0019981_st    0.000000\n",
      "MIMAT0019982_st    0.000000\n",
      "MIMAT0019983_st    0.000000\n",
      "MIMAT0019984_st    0.000000\n",
      "MIMAT0019985_st    0.000000\n",
      "MIMAT0000062_st    0.000000\n",
      "MIMAT0020300_st    0.000000\n",
      "MIMAT0020541_st    0.000000\n",
      "MIMAT0020600_st    0.000000\n",
      "MIMAT0020601_st    0.000000\n",
      "MIMAT0020602_st    0.000000\n",
      "MIMAT0020603_st    0.000000\n",
      "MIMAT0020924_st    0.000000\n",
      "MIMAT0020925_st    0.000000\n",
      "MIMAT0020299_st    0.000000\n",
      "Name: perm_mean, dtype: float64\n",
      "\n",
      "Treinando RandomForest para: Grupo_PDAC\n",
      "RF salvo em: c:\\Users\\cassi\\OneDrive\\Documentos\\1-Programas\\TCC\\models_Tree\\modelo_RF_Grupo_PDAC.joblib\n",
      "Calculando permutation importance (pode demorar) ...\n",
      "\n",
      "Top 20 (impurity)\n",
      "              feature  impurity_imp\n",
      "1481  MIMAT0019745_st      0.044333\n",
      "1249  MIMAT0018954_st      0.041262\n",
      "1351  MIMAT0019059_st      0.034725\n",
      "939   MIMAT0015025_st      0.032017\n",
      "997   MIMAT0015086_st      0.030189\n",
      "614   MIMAT0004784_st      0.021428\n",
      "1100  MIMAT0017991_st      0.020917\n",
      "2541  MIMAT0030991_st      0.018559\n",
      "738   MIMAT0005829_st      0.017456\n",
      "500   MIMAT0004518_st      0.014058\n",
      "624   MIMAT0004800_st      0.013882\n",
      "357   MIMAT0003251_st      0.013474\n",
      "1218  MIMAT0018446_st      0.011933\n",
      "137   MIMAT0000646_st      0.011548\n",
      "2561  MIMAT0031011_st      0.010289\n",
      "1793  MIMAT0022264_st      0.009699\n",
      "788   MIMAT0005915_st      0.008965\n",
      "1894  MIMAT0022723_st      0.008942\n",
      "992   MIMAT0015081_st      0.008534\n",
      "28    MIMAT0000090_st      0.008073\n",
      "\n",
      "Top 20 (permutation)\n",
      "MIMAT0015079_st    0.015094\n",
      "MIMAT0015025_st    0.015094\n",
      "MIMAT0004784_st    0.011321\n",
      "MIMAT0000646_st    0.009434\n",
      "MIMAT0022264_st    0.007547\n",
      "MIMAT0004518_st    0.007547\n",
      "MIMAT0015086_st    0.005660\n",
      "MIMAT0018938_st    0.003774\n",
      "MIMAT0020601_st    0.000000\n",
      "MIMAT0020600_st    0.000000\n",
      "MIMAT0020541_st    0.000000\n",
      "MIMAT0020300_st    0.000000\n",
      "MIMAT0019981_st    0.000000\n",
      "MIMAT0020602_st    0.000000\n",
      "MIMAT0020299_st    0.000000\n",
      "MIMAT0020603_st    0.000000\n",
      "MIMAT0020924_st    0.000000\n",
      "MIMAT0020925_st    0.000000\n",
      "MIMAT0019985_st    0.000000\n",
      "MIMAT0020956_st    0.000000\n",
      "Name: perm_mean, dtype: float64\n",
      "\n",
      "RandomForest training + permutation importance completo.\n"
     ]
    }
   ],
   "source": [
    "# Treinar RandomForest por classe e calcular permutation importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "rf_models = {}\n",
    "rf_importances = {}\n",
    "rf_perm = {}\n",
    "\n",
    "for classe, (X, y) in dados_balanceados.items():\n",
    "    print(f\"\\nTreinando RandomForest para: {classe}\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # salvar\n",
    "    nome_rf = f\"modelo_RF_{classe.replace(' ', '_')}.joblib\"\n",
    "    caminho_rf = os.path.join(os.getcwd(), 'models_Tree', nome_rf)\n",
    "    dump(rf, caminho_rf)\n",
    "    print(f\"RF salvo em: {caminho_rf}\")\n",
    "\n",
    "    # feature importances\n",
    "    imp = rf.feature_importances_\n",
    "    rf_models[classe] = rf\n",
    "    rf_importances[classe] = imp\n",
    "\n",
    "    # permutation importance (mais robusto)\n",
    "    print('Calculando permutation importance (pode demorar) ...')\n",
    "    perm = permutation_importance(rf, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "    rf_perm[classe] = perm\n",
    "\n",
    "    # mostrar top20 por impurity e por permutation\n",
    "    cols = pd.Index(dados_processados.columns)\n",
    "    imp_df = pd.DataFrame({'feature': cols, 'impurity_imp': imp}).sort_values('impurity_imp', ascending=False)\n",
    "    perm_means = pd.Series(perm.importances_mean, index=cols)\n",
    "    perm_df = perm_means.sort_values(ascending=False).rename('perm_mean')\n",
    "\n",
    "    print('\\nTop 20 (impurity)')\n",
    "    print(imp_df.head(20))\n",
    "    print('\\nTop 20 (permutation)')\n",
    "    print(perm_df.head(20))\n",
    "\n",
    "# Guardar dicion√°rios se quiser mais tarde\n",
    "print('\\nRandomForest training + permutation importance completo.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7ed7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "# usar X_test e y_test que foram produzidos quando treinou o RF para Grupo_PDAC.\n",
    "# Supondo que durante o loop de treino voc√™ guardou X_test_pdac e y_test_pdac; \n",
    "# se n√£o, re-split dos dados balanceados para Grupo_PDAC com same random_state.\n",
    "\n",
    "perm_pdac = permutation_importance(\n",
    "    rf_models['Grupo_PDAC'],\n",
    "    X_test,             # o X_test correspondente ao modelo PDAC\n",
    "    y_test,             # o y_test correspondente\n",
    "    n_repeats=50,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    scoring='roc_auc'   # ou 'balanced_accuracy' / outra m√©trica\n",
    ")\n",
    "pd.Series(perm_pdac.importances_mean, index=rf_models['Grupo_PDAC'].feature_names_in_).sort_values(ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28cff70",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Inspecionar √°rvore treinada (DecisionTree) - export_text (mostra top splits)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m export_text\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Primeiro mostrar as √°rvores de decis√£o\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m classe \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrupo_Controle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrupo_PDAC\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# Inspecionar √°rvore treinada (DecisionTree) - export_text (mostra top splits)\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "for classe in ['Grupo_Controle', 'Grupo_PDAC']:\n",
    "    modelo_path = os.path.join(os.getcwd(), 'models_Tree', f\"modelo_{classe.replace(' ', '_')}.joblib\")\n",
    "    if os.path.exists(modelo_path):\n",
    "        tree_model = load(modelo_path)\n",
    "        print(f\"\\n--- √Årvore para {classe} (primeiras 4 n√≠veis) ---\")\n",
    "        try:\n",
    "            tree_text = export_text(tree_model, feature_names=list(dados_processados.columns), max_depth=4)\n",
    "            print(tree_text[:4000])  # limitar sa√≠da\n",
    "        except Exception as e:\n",
    "            print('Falha export_text:', e)\n",
    "    else:\n",
    "        print('Modelo n√£o encontrado:', modelo_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2973b505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== An√°lise de Import√¢ncia das Features na Random Forest ===\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "'seaborn' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cassi\\miniconda3\\Lib\\site-packages\\matplotlib\\style\\core.py:129\u001b[39m, in \u001b[36muse\u001b[39m\u001b[34m(style)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     style = \u001b[43m_rc_params_in_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cassi\\miniconda3\\Lib\\site-packages\\matplotlib\\__init__.py:903\u001b[39m, in \u001b[36m_rc_params_in_file\u001b[39m\u001b[34m(fname, transform, fail_on_error)\u001b[39m\n\u001b[32m    902\u001b[39m rc_temp = {}\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_file_or_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfd\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cassi\\miniconda3\\Lib\\contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.gen)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cassi\\miniconda3\\Lib\\site-packages\\matplotlib\\__init__.py:880\u001b[39m, in \u001b[36m_open_file_or_url\u001b[39m\u001b[34m(fname)\u001b[39m\n\u001b[32m    879\u001b[39m fname = os.path.expanduser(fname)\n\u001b[32m--> \u001b[39m\u001b[32m880\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fname, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    881\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'seaborn'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== An√°lise de Import√¢ncia das Features na Random Forest ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Configurar o estilo do matplotlib\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m.\u001b[49m\u001b[43muse\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mseaborn\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m fig, axes = plt.subplots(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, figsize=(\u001b[32m20\u001b[39m, \u001b[32m16\u001b[39m))\n\u001b[32m     10\u001b[39m fig.suptitle(\u001b[33m'\u001b[39m\u001b[33mAn√°lise de Import√¢ncia das Features por Random Forest\u001b[39m\u001b[33m'\u001b[39m, fontsize=\u001b[32m16\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cassi\\miniconda3\\Lib\\site-packages\\matplotlib\\style\\core.py:131\u001b[39m, in \u001b[36muse\u001b[39m\u001b[34m(style)\u001b[39m\n\u001b[32m    129\u001b[39m         style = _rc_params_in_file(style)\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    132\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstyle\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m is not a valid package style, path of style \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    133\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfile, URL of style file, or library style name (library \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mstyles are listed in `style.available`)\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    135\u001b[39m filtered = {}\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m style:  \u001b[38;5;66;03m# don't trigger RcParams.__getitem__('backend')\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: 'seaborn' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Agora criar visualiza√ß√µes para Random Forest\n",
    "print(\"\\n=== An√°lise de Import√¢ncia das Features na Random Forest ===\")\n",
    "\n",
    "# Configurar o estilo do matplotlib\n",
    "plt.style.use('seaborn')\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "fig.suptitle('An√°lise de Import√¢ncia das Features por Random Forest', fontsize=16)\n",
    "\n",
    "for idx, classe in enumerate(['Grupo_Controle', 'Grupo_PDAC']):\n",
    "    if classe in rf_importances and classe in rf_perm:\n",
    "        # Preparar dados para plotting\n",
    "        imp = rf_importances[classe]\n",
    "        perm = rf_perm[classe]\n",
    "        features = dados_processados.columns\n",
    "        \n",
    "        # DataFrame com as import√¢ncias\n",
    "        imp_df = pd.DataFrame({\n",
    "            'Feature': features,\n",
    "            'Import√¢ncia (MDI)': imp,\n",
    "            'Import√¢ncia (Permuta√ß√£o)': perm.importances_mean\n",
    "        }).sort_values('Import√¢ncia (MDI)', ascending=True)\n",
    "        \n",
    "        # Plotar top 15 features por MDI\n",
    "        top_15 = imp_df.nlargest(15, 'Import√¢ncia (MDI)')\n",
    "        \n",
    "        # Gr√°fico de barras horizontais para MDI\n",
    "        sns.barh(y='Feature', x='Import√¢ncia (MDI)', \n",
    "                data=top_15.iloc[:15], \n",
    "                ax=axes[idx, 0],\n",
    "                color='skyblue')\n",
    "        axes[idx, 0].set_title(f'Top 15 Features - MDI\\n{classe}')\n",
    "        axes[idx, 0].set_xlabel('Import√¢ncia (Mean Decrease in Impurity)')\n",
    "        \n",
    "        # Gr√°fico de barras horizontais para Permuta√ß√£o\n",
    "        sns.barh(y='Feature', x='Import√¢ncia (Permuta√ß√£o)', \n",
    "                data=top_15.iloc[:15], \n",
    "                ax=axes[idx, 1],\n",
    "                color='lightcoral')\n",
    "        axes[idx, 1].set_title(f'Top 15 Features - Permuta√ß√£o\\n{classe}')\n",
    "        axes[idx, 1].set_xlabel('Import√¢ncia (Permuta√ß√£o)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Adicionar correla√ß√£o entre as duas m√©tricas\n",
    "for classe in ['Grupo_Controle', 'Grupo_PDAC']:\n",
    "    if classe in rf_importances and classe in rf_perm:\n",
    "        mdi = rf_importances[classe]\n",
    "        perm = rf_perm[classe].importances_mean\n",
    "        corr = np.corrcoef(mdi, perm)[0,1]\n",
    "        print(f\"\\nCorrela√ß√£o entre MDI e Permuta√ß√£o para {classe}: {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa118585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos carregados com sucesso!\n",
      "\n",
      "\n",
      "Realizando infer√™ncia...\n",
      "\n",
      "Probabilidade para 'Grupo_Controle': 1.0000\n",
      "Probabilidade para 'Grupo_PDAC': 0.0000\n",
      "\n",
      "Classe predita: Grupo_Controle (Probabilidade: 1.0000)\n",
      "\n",
      "Probabilidades ordenadas:\n",
      "                Probabilidade (%)\n",
      "Grupo_Controle              100.0\n",
      "Grupo_PDAC                    0.0\n"
     ]
    }
   ],
   "source": [
    "# --- CARREGAR NORMALIZADOR ---\n",
    "normalizador = load(open(\"models_Tree/normalizador_TCC_Tree.model\", \"rb\"))\n",
    "\n",
    "# --- CARREGAR MODELOS ---\n",
    "caminho_modelos = os.path.join(os.getcwd(), 'models_Tree')\n",
    "nomes_classes = ['Grupo_Controle', 'Grupo_PDAC']\n",
    "\n",
    "modelos = {}\n",
    "for classe in nomes_classes:\n",
    "    nome_arquivo = f\"modelo_{classe.replace(' ', '_')}.joblib\"\n",
    "    caminho_arquivo = os.path.join(caminho_modelos, nome_arquivo)\n",
    "    modelos[classe] = load(caminho_arquivo)\n",
    "\n",
    "print(\"Modelos carregados com sucesso!\\n\")\n",
    "\n",
    "\n",
    "# Gerar amostras random\n",
    "num_mirnas = 2579\n",
    "\n",
    "# gerar valores aleat√≥rios entre -5 e 5 (ajuste conforme sua base)\n",
    "mirna_valores = [round(random.uniform(-5, 5), 4) for _ in range(num_mirnas)]\n",
    "\n",
    "# criar nomes de colunas (ex: miR_1, miR_2, ..., miR_2579)\n",
    "colunas_mirna = [f\"miR_{i+1}\" for i in range(num_mirnas)]\n",
    "\n",
    "# criar DataFrame\n",
    "paciente_mirna_df = pd.DataFrame([mirna_valores], columns=colunas_mirna)\n",
    "\n",
    "\n",
    "# --- NORMALIZAR AMOSTRA ---\n",
    "# Garantir que o paciente tenha as mesmas colunas que o normalizador esperava\n",
    "colunas_esperadas = normalizador.feature_names_in_\n",
    "\n",
    "# Criar c√≥pia da amostra e ajustar colunas\n",
    "paciente_mirna_df_alinhado = paciente_mirna_df.reindex(columns=colunas_esperadas, fill_value=0)\n",
    "\n",
    "# Agora normalizar\n",
    "paciente_mirna_norm = normalizador.transform(paciente_mirna_df_alinhado)\n",
    "paciente_mirna_norm_df = pd.DataFrame(paciente_mirna_norm, columns=colunas_esperadas)\n",
    "\n",
    "# --- AJUSTAR COLUNAS ---\n",
    "# usar colunas esperadas de um dos modelos (garante compatibilidade)\n",
    "colunas_esperadas = modelos['Grupo_PDAC'].feature_names_in_\n",
    "\n",
    "# reindexar para garantir mesma ordem e preencher faltantes com 0\n",
    "paciente_final_df = paciente_mirna_norm_df.reindex(columns=colunas_esperadas).fillna(0)\n",
    "\n",
    "# --- FUNCAO DE INFERENCIA ---\n",
    "def fazer_inferencia(paciente_df):\n",
    "    resultados = {}\n",
    "    print(\"\\nRealizando infer√™ncia...\\n\")\n",
    "\n",
    "    paciente_array = paciente_df  # manter DataFrame para preservar nomes das features\n",
    "\n",
    "    for classe, modelo in modelos.items():\n",
    "        proba = modelo.predict_proba(paciente_array)[0][1]\n",
    "        resultados[classe] = proba\n",
    "        print(f\"Probabilidade para '{classe}': {proba:.4f}\")\n",
    "\n",
    "    classe_predita = max(resultados, key=resultados.get)\n",
    "    print(f\"\\nClasse predita: {classe_predita} (Probabilidade: {resultados[classe_predita]:.4f})\")\n",
    "\n",
    "    return classe_predita, resultados\n",
    "\n",
    "# --- EXECUTAR INFERENCIA ---\n",
    "classe_predita, probabilidades = fazer_inferencia(paciente_final_df)\n",
    "\n",
    "# --- MOSTRAR RESULTADOS ---\n",
    "df_prob = pd.DataFrame.from_dict(probabilidades, orient='index', columns=['Probabilidade'])\n",
    "df_prob = df_prob.sort_values(by='Probabilidade', ascending=False)\n",
    "df_prob['Probabilidade (%)'] = df_prob['Probabilidade'] * 100\n",
    "\n",
    "print(\"\\nProbabilidades ordenadas:\")\n",
    "print(df_prob[['Probabilidade (%)']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
